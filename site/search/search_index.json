{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"LinAlgKit Documentation","text":"<p>Welcome to the LinAlgKit docs. This project provides a comprehensive, Python-first linear algebra and deep learning math library built on NumPy.</p> <p>Version: 0.2.1 | GitHub | PyPI</p>"},{"location":"#features","title":"Features","text":"<ul> <li>\ud83d\udd22 Matrix Operations - Full matrix algebra with decompositions</li> <li>\ud83e\udde0 Deep Learning Functions - Activations, losses, normalization</li> <li>\u26a1 High Performance - Numba JIT acceleration up to 13x faster</li> <li>\ud83d\udc0d Pythonic API - Clean, intuitive interface</li> </ul>"},{"location":"#quick-install","title":"Quick Install","text":"<pre><code>pip install LinAlgKit\n</code></pre> <p>For high-performance functions:</p> <pre><code>pip install LinAlgKit numba\n</code></pre>"},{"location":"#quick-start","title":"Quick Start","text":"<pre><code>import LinAlgKit as lk\nimport numpy as np\n\n# Create matrices\nA = lk.Matrix.from_numpy(np.array([[1.0, 2.0], [3.0, 4.0]]))\n\n# Matrix operations\nprint(A.determinant())  # -2.0\nprint(A.T.to_numpy())   # Transpose\n\n# Decompositions\nL, U, P = A.lu()\nQ, R = A.qr()\n\n# Deep learning functions\nx = np.random.randn(100, 10)\noutput = lk.relu(x)\nprobs = lk.softmax(x)\nloss = lk.cross_entropy_loss(probs, targets)\n</code></pre>"},{"location":"#documentation","title":"Documentation","text":"Section Description Getting Started Installation, basic usage, examples API Reference Complete API documentation Deep Learning Activations, losses, normalization Performance Benchmarks and optimization Release Notes Version history and changelog"},{"location":"#whats-new-in-v021","title":"What's New in v0.2.1","text":""},{"location":"#high-performance-fast-module","title":"High-Performance <code>fast</code> Module","text":"<pre><code>from LinAlgKit import fast\n\n# Up to 13x faster with Numba JIT\nloss = fast.fast_mse_loss(pred, target)\noutput = fast.fast_relu(x)\n</code></pre>"},{"location":"#performance-improvements","title":"Performance Improvements","text":"Function Speedup <code>mae_loss</code> 13.1x <code>mse_loss</code> 12.0x <code>leaky_relu</code> 4.4x <code>gelu</code> 2.6x"},{"location":"#in-place-operations","title":"In-Place Operations","text":"<pre><code>A.add_(B)      # No memory allocation\nA.mul_(2.0)    # Faster than A = A * 2\n</code></pre>"},{"location":"#license","title":"License","text":"<p>MIT License - see LICENSE</p>"},{"location":"api/","title":"LinAlgKit API Reference","text":"<p>A comprehensive guide to all classes, methods, and functions in LinAlgKit.</p>"},{"location":"api/#table-of-contents","title":"Table of Contents","text":"<ol> <li>Installation</li> <li>Quick Start</li> <li>Matrix Classes</li> <li>Matrix (float64)</li> <li>MatrixF (float32)</li> <li>MatrixI (int)</li> <li>Matrix Methods</li> <li>Constructors</li> <li>Static Constructors</li> <li>Properties</li> <li>NumPy Interop</li> <li>Arithmetic Operations</li> <li>Matrix Operations</li> <li>Element Access</li> <li>Functional API</li> <li>Examples</li> <li>Error Handling</li> </ol>"},{"location":"api/#installation","title":"Installation","text":"<pre><code>pip install LinAlgKit\n</code></pre> <p>Requirements: - Python 3.8+ - NumPy &gt;= 1.22</p>"},{"location":"api/#quick-start","title":"Quick Start","text":"<pre><code>import LinAlgKit as lk\nimport numpy as np\n\n# Create a matrix from a NumPy array\nA = lk.Matrix.from_numpy(np.array([[1.0, 2.0], [3.0, 4.0]]))\n\n# Create an identity matrix\nI = lk.Matrix.identity(2)\n\n# Perform operations\nC = A + I                    # Matrix addition\nAT = A.transpose()           # Transpose\ndet_A = A.determinant()      # Determinant\ntr_A = A.trace()             # Trace\n\n# Convert back to NumPy\nresult = C.to_numpy()\nprint(result)\n# [[2. 2.]\n#  [3. 5.]]\n</code></pre>"},{"location":"api/#matrix-classes","title":"Matrix Classes","text":"<p>LinAlgKit provides three matrix classes optimized for different numeric types:</p> Class NumPy dtype Use Case <code>Matrix</code> <code>float64</code> General-purpose, high precision <code>MatrixF</code> <code>float32</code> Memory-efficient, GPU-compatible <code>MatrixI</code> <code>int</code> Integer arithmetic, indexing matrices <p>All three classes share the same API, differing only in their underlying data type.</p>"},{"location":"api/#matrix-float64","title":"Matrix (float64)","text":"<p>Double-precision floating-point matrix. This is the default and recommended class for most linear algebra operations.</p> <pre><code>import LinAlgKit as lk\n\n# Create a 3x3 matrix filled with zeros\nA = lk.Matrix(3, 3)\n\n# Create a 2x4 matrix filled with value 5.0\nB = lk.Matrix(2, 4, 5.0)\n</code></pre> <p>Precision: 64-bit floating point (~15-17 significant decimal digits)</p>"},{"location":"api/#matrixf-float32","title":"MatrixF (float32)","text":"<p>Single-precision floating-point matrix. Useful for memory-constrained applications or GPU interoperability.</p> <pre><code>import LinAlgKit as lk\n\n# Create a single-precision matrix\nA = lk.MatrixF(3, 3, 1.0)\n</code></pre> <p>Precision: 32-bit floating point (~6-9 significant decimal digits)</p>"},{"location":"api/#matrixi-int","title":"MatrixI (int)","text":"<p>Integer matrix. Ideal for discrete mathematics, graph adjacency matrices, or counting operations.</p> <pre><code>import LinAlgKit as lk\n\n# Create an integer matrix\nA = lk.MatrixI(3, 3, 1)\n</code></pre> <p>Precision: Platform-dependent integer (typically 32 or 64 bits)</p>"},{"location":"api/#matrix-methods","title":"Matrix Methods","text":""},{"location":"api/#constructors","title":"Constructors","text":""},{"location":"api/#matrixrows-cols-value00","title":"<code>Matrix(rows, cols, value=0.0)</code>","text":"<p>Creates a new matrix with the specified dimensions, filled with a constant value.</p> <p>Parameters: | Parameter | Type | Default | Description | |-----------|------|---------|-------------| | <code>rows</code> | <code>int</code> | Required | Number of rows | | <code>cols</code> | <code>int</code> | Required | Number of columns | | <code>value</code> | <code>float</code> | <code>0.0</code> | Fill value for all elements |</p> <p>Returns: <code>Matrix</code> \u2014 A new matrix instance</p> <p>Example:</p> <pre><code>import LinAlgKit as lk\n\n# 3x3 zero matrix\nzeros = lk.Matrix(3, 3)\n\n# 2x5 matrix filled with 7.5\nfilled = lk.Matrix(2, 5, 7.5)\n\n# Empty matrix (0x0)\nempty = lk.Matrix()\n</code></pre> <p>Time Complexity: O(rows \u00d7 cols)</p>"},{"location":"api/#static-constructors","title":"Static Constructors","text":""},{"location":"api/#matrixidentitysize","title":"<code>Matrix.identity(size)</code>","text":"<p>Creates a square identity matrix of the specified size.</p> <p>Parameters: | Parameter | Type | Description | |-----------|------|-------------| | <code>size</code> | <code>int</code> | Dimension of the square matrix |</p> <p>Returns: <code>Matrix</code> \u2014 Identity matrix with 1s on diagonal, 0s elsewhere</p> <p>Mathematical Definition:</p> <pre><code>I[i,j] = 1 if i == j\nI[i,j] = 0 if i != j\n</code></pre> <p>Example:</p> <pre><code>I = lk.Matrix.identity(3)\nprint(I.to_numpy())\n# [[1. 0. 0.]\n#  [0. 1. 0.]\n#  [0. 0. 1.]]\n</code></pre> <p>Time Complexity: O(n\u00b2) where n = size</p>"},{"location":"api/#matrixzerosrows-cols","title":"<code>Matrix.zeros(rows, cols)</code>","text":"<p>Creates a matrix filled with zeros.</p> <p>Parameters: | Parameter | Type | Description | |-----------|------|-------------| | <code>rows</code> | <code>int</code> | Number of rows | | <code>cols</code> | <code>int</code> | Number of columns |</p> <p>Returns: <code>Matrix</code> \u2014 Zero matrix</p> <p>Example:</p> <pre><code>Z = lk.Matrix.zeros(2, 3)\nprint(Z.to_numpy())\n# [[0. 0. 0.]\n#  [0. 0. 0.]]\n</code></pre> <p>Time Complexity: O(rows \u00d7 cols)</p>"},{"location":"api/#matrixonesrows-cols","title":"<code>Matrix.ones(rows, cols)</code>","text":"<p>Creates a matrix filled with ones.</p> <p>Parameters: | Parameter | Type | Description | |-----------|------|-------------| | <code>rows</code> | <code>int</code> | Number of rows | | <code>cols</code> | <code>int</code> | Number of columns |</p> <p>Returns: <code>Matrix</code> \u2014 Matrix of ones</p> <p>Example:</p> <pre><code>O = lk.Matrix.ones(2, 3)\nprint(O.to_numpy())\n# [[1. 1. 1.]\n#  [1. 1. 1.]]\n</code></pre> <p>Time Complexity: O(rows \u00d7 cols)</p>"},{"location":"api/#properties","title":"Properties","text":""},{"location":"api/#rows","title":"<code>rows</code>","text":"<p>Returns the number of rows in the matrix.</p> <p>Type: <code>int</code> (read-only)</p> <p>Example:</p> <pre><code>A = lk.Matrix(3, 5)\nprint(A.rows)  # 3\n</code></pre>"},{"location":"api/#cols","title":"<code>cols</code>","text":"<p>Returns the number of columns in the matrix.</p> <p>Type: <code>int</code> (read-only)</p> <p>Example:</p> <pre><code>A = lk.Matrix(3, 5)\nprint(A.cols)  # 5\n</code></pre>"},{"location":"api/#numpy-interoperability","title":"NumPy Interoperability","text":""},{"location":"api/#matrixfrom_numpyarr","title":"<code>Matrix.from_numpy(arr)</code>","text":"<p>Creates a matrix from a 2D NumPy array.</p> <p>Parameters: | Parameter | Type | Description | |-----------|------|-------------| | <code>arr</code> | <code>numpy.ndarray</code> | 2D NumPy array |</p> <p>Returns: <code>Matrix</code> \u2014 New matrix containing a copy of the array data</p> <p>Raises: - <code>ValueError</code> \u2014 If the array is not 2-dimensional</p> <p>Example:</p> <pre><code>import numpy as np\nimport LinAlgKit as lk\n\n# From a NumPy array\narr = np.array([[1.0, 2.0, 3.0],\n                [4.0, 5.0, 6.0]])\nA = lk.Matrix.from_numpy(arr)\n\n# Works with any array-like\nB = lk.Matrix.from_numpy([[1, 2], [3, 4]])\n</code></pre> <p>Note: This method creates a copy of the data. Modifications to the original array will not affect the matrix.</p> <p>Time Complexity: O(rows \u00d7 cols)</p>"},{"location":"api/#to_numpy","title":"<code>to_numpy()</code>","text":"<p>Converts the matrix to a 2D NumPy array.</p> <p>Returns: <code>numpy.ndarray</code> \u2014 A copy of the matrix data as a 2D array</p> <p>Example:</p> <pre><code>A = lk.Matrix.identity(2)\narr = A.to_numpy()\nprint(type(arr))  # &lt;class 'numpy.ndarray'&gt;\nprint(arr)\n# [[1. 0.]\n#  [0. 1.]]\n</code></pre> <p>Note: This method returns a copy. Modifications to the returned array will not affect the original matrix.</p> <p>Time Complexity: O(rows \u00d7 cols)</p>"},{"location":"api/#arithmetic-operations","title":"Arithmetic Operations","text":""},{"location":"api/#__add__other-matrix-addition","title":"<code>__add__(other)</code> \u2014 Matrix Addition","text":"<p>Adds two matrices element-wise.</p> <p>Operator: <code>A + B</code></p> <p>Parameters: | Parameter | Type | Description | |-----------|------|-------------| | <code>other</code> | <code>Matrix</code> | Matrix to add (must have same dimensions) |</p> <p>Returns: <code>Matrix</code> \u2014 Element-wise sum</p> <p>Mathematical Definition:</p> <pre><code>C[i,j] = A[i,j] + B[i,j]\n</code></pre> <p>Example:</p> <pre><code>A = lk.Matrix.from_numpy([[1, 2], [3, 4]])\nB = lk.Matrix.from_numpy([[5, 6], [7, 8]])\nC = A + B\nprint(C.to_numpy())\n# [[ 6.  8.]\n#  [10. 12.]]\n</code></pre> <p>Time Complexity: O(rows \u00d7 cols)</p>"},{"location":"api/#__sub__other-matrix-subtraction","title":"<code>__sub__(other)</code> \u2014 Matrix Subtraction","text":"<p>Subtracts one matrix from another element-wise.</p> <p>Operator: <code>A - B</code></p> <p>Parameters: | Parameter | Type | Description | |-----------|------|-------------| | <code>other</code> | <code>Matrix</code> | Matrix to subtract (must have same dimensions) |</p> <p>Returns: <code>Matrix</code> \u2014 Element-wise difference</p> <p>Mathematical Definition:</p> <pre><code>C[i,j] = A[i,j] - B[i,j]\n</code></pre> <p>Example:</p> <pre><code>A = lk.Matrix.from_numpy([[5, 6], [7, 8]])\nB = lk.Matrix.from_numpy([[1, 2], [3, 4]])\nC = A - B\nprint(C.to_numpy())\n# [[4. 4.]\n#  [4. 4.]]\n</code></pre> <p>Time Complexity: O(rows \u00d7 cols)</p>"},{"location":"api/#__mul__other-matrix-multiplication-scalar-multiplication","title":"<code>__mul__(other)</code> \u2014 Matrix Multiplication / Scalar Multiplication","text":"<p>Performs matrix multiplication (if <code>other</code> is a Matrix) or scalar multiplication (if <code>other</code> is a number).</p> <p>Operator: <code>A * B</code> or <code>A * scalar</code></p> <p>Parameters: | Parameter | Type | Description | |-----------|------|-------------| | <code>other</code> | <code>Matrix</code> or <code>Number</code> | Matrix or scalar to multiply |</p> <p>Returns: <code>Matrix</code> \u2014 Product</p> <p>Matrix Multiplication (A * B):</p> <pre><code>C[i,j] = \u03a3(k=0 to n-1) A[i,k] * B[k,j]\n</code></pre> <ul> <li>Requires: A.cols == B.rows</li> <li>Result shape: (A.rows, B.cols)</li> </ul> <p>Scalar Multiplication (A * s):</p> <pre><code>C[i,j] = A[i,j] * s\n</code></pre> <p>Example:</p> <pre><code># Matrix multiplication\nA = lk.Matrix.from_numpy([[1, 2], [3, 4]])\nB = lk.Matrix.from_numpy([[5, 6], [7, 8]])\nC = A * B\nprint(C.to_numpy())\n# [[19. 22.]\n#  [43. 50.]]\n\n# Scalar multiplication\nD = A * 2\nprint(D.to_numpy())\n# [[2. 4.]\n#  [6. 8.]]\n</code></pre> <p>Time Complexity: - Matrix multiplication: O(n\u00b3) for n\u00d7n matrices - Scalar multiplication: O(rows \u00d7 cols)</p>"},{"location":"api/#__rmul__scalar-left-scalar-multiplication","title":"<code>__rmul__(scalar)</code> \u2014 Left Scalar Multiplication","text":"<p>Multiplies a matrix by a scalar on the left.</p> <p>Operator: <code>scalar * A</code></p> <p>Parameters: | Parameter | Type | Description | |-----------|------|-------------| | <code>scalar</code> | <code>Number</code> | Scalar multiplier |</p> <p>Returns: <code>Matrix</code> \u2014 Scaled matrix</p> <p>Example:</p> <pre><code>A = lk.Matrix.from_numpy([[1, 2], [3, 4]])\nB = 3 * A\nprint(B.to_numpy())\n# [[3. 6.]\n#  [9. 12.]]\n</code></pre> <p>Time Complexity: O(rows \u00d7 cols)</p>"},{"location":"api/#matrix-operations","title":"Matrix Operations","text":""},{"location":"api/#transpose","title":"<code>transpose()</code>","text":"<p>Returns the transpose of the matrix.</p> <p>Returns: <code>Matrix</code> \u2014 Transposed matrix</p> <p>Mathematical Definition:</p> <pre><code>B[i,j] = A[j,i]\n</code></pre> <p>Example:</p> <pre><code>A = lk.Matrix.from_numpy([[1, 2, 3],\n                          [4, 5, 6]])\nAT = A.transpose()\nprint(AT.to_numpy())\n# [[1. 4.]\n#  [2. 5.]\n#  [3. 6.]]\n</code></pre> <p>Time Complexity: O(rows \u00d7 cols)</p>"},{"location":"api/#trace","title":"<code>trace()</code>","text":"<p>Computes the trace (sum of diagonal elements) of a matrix.</p> <p>Returns: <code>Number</code> \u2014 Sum of diagonal elements</p> <p>Mathematical Definition:</p> <pre><code>trace(A) = \u03a3(i=0 to min(rows,cols)-1) A[i,i]\n</code></pre> <p>Example:</p> <pre><code>A = lk.Matrix.from_numpy([[1, 2, 3],\n                          [4, 5, 6],\n                          [7, 8, 9]])\nprint(A.trace())  # 15.0 (1 + 5 + 9)\n</code></pre> <p>Time Complexity: O(min(rows, cols))</p>"},{"location":"api/#determinant","title":"<code>determinant()</code>","text":"<p>Computes the determinant of a square matrix using LU decomposition.</p> <p>Returns: <code>Number</code> \u2014 Determinant value</p> <p>Raises: - Undefined behavior for non-square matrices</p> <p>Mathematical Properties: - det(I) = 1 (identity matrix) - det(AB) = det(A) \u00d7 det(B) - det(A^T) = det(A) - det(cA) = c^n \u00d7 det(A) for n\u00d7n matrix</p> <p>Example:</p> <pre><code>A = lk.Matrix.from_numpy([[1, 2],\n                          [3, 4]])\nprint(A.determinant())  # -2.0\n\n# Singular matrix\nB = lk.Matrix.from_numpy([[1, 2],\n                          [2, 4]])\nprint(B.determinant())  # 0.0\n</code></pre> <p>Time Complexity: O(n\u00b3) using LU decomposition</p>"},{"location":"api/#determinant_naive","title":"<code>determinant_naive()</code>","text":"<p>Computes the determinant using recursive cofactor expansion. Provided for educational purposes and small matrices.</p> <p>Returns: <code>Number</code> \u2014 Determinant value</p> <p>Raises: - <code>ValueError</code> \u2014 If matrix is not square</p> <p>Warning: This method has O(n!) time complexity. Use <code>determinant()</code> for matrices larger than 4\u00d74.</p> <p>Example:</p> <pre><code>A = lk.Matrix.from_numpy([[1, 2],\n                          [3, 4]])\nprint(A.determinant_naive())  # -2.0\n</code></pre> <p>Time Complexity: O(n!) \u2014 factorial, use only for small matrices</p>"},{"location":"api/#element-access","title":"Element Access","text":""},{"location":"api/#__getitem__idx-get-element","title":"<code>__getitem__(idx)</code> \u2014 Get Element","text":"<p>Access a single element by row and column index.</p> <p>Operator: <code>A[row, col]</code></p> <p>Parameters: | Parameter | Type | Description | |-----------|------|-------------| | <code>idx</code> | <code>Tuple[int, int]</code> | (row, column) indices, 0-indexed |</p> <p>Returns: <code>Number</code> \u2014 Element value</p> <p>Example:</p> <pre><code>A = lk.Matrix.from_numpy([[1, 2, 3],\n                          [4, 5, 6]])\nprint(A[0, 0])  # 1.0\nprint(A[1, 2])  # 6.0\n</code></pre>"},{"location":"api/#__setitem__idx-value-set-element","title":"<code>__setitem__(idx, value)</code> \u2014 Set Element","text":"<p>Set a single element by row and column index.</p> <p>Operator: <code>A[row, col] = value</code></p> <p>Parameters: | Parameter | Type | Description | |-----------|------|-------------| | <code>idx</code> | <code>Tuple[int, int]</code> | (row, column) indices, 0-indexed | | <code>value</code> | <code>Number</code> | New value |</p> <p>Example:</p> <pre><code>A = lk.Matrix.zeros(2, 2)\nA[0, 0] = 1.0\nA[1, 1] = 1.0\nprint(A.to_numpy())\n# [[1. 0.]\n#  [0. 1.]]\n</code></pre>"},{"location":"api/#functional-api","title":"Functional API","text":"<p>LinAlgKit also provides NumPy-compatible functional helpers for working directly with arrays.</p>"},{"location":"api/#arraya-dtypenone","title":"<code>array(a, dtype=None)</code>","text":"<p>Creates a NumPy array from nested lists.</p> <p>Parameters: | Parameter | Type | Description | |-----------|------|-------------| | <code>a</code> | <code>Iterable[Iterable[Number]]</code> | Nested list of numbers | | <code>dtype</code> | <code>str</code> or <code>None</code> | Optional data type |</p> <p>Returns: <code>numpy.ndarray</code></p> <p>Example:</p> <pre><code>from LinAlgKit import array\nA = array([[1, 2], [3, 4]])\n</code></pre>"},{"location":"api/#zerosshape-dtypenone","title":"<code>zeros(shape, dtype=None)</code>","text":"<p>Creates a zero-filled NumPy array.</p> <p>Parameters: | Parameter | Type | Description | |-----------|------|-------------| | <code>shape</code> | <code>Tuple[int, int]</code> | (rows, cols) | | <code>dtype</code> | <code>str</code> or <code>None</code> | Optional data type |</p> <p>Returns: <code>numpy.ndarray</code></p> <p>Example:</p> <pre><code>from LinAlgKit import zeros\nZ = zeros((3, 3))\n</code></pre>"},{"location":"api/#onesshape-dtypenone","title":"<code>ones(shape, dtype=None)</code>","text":"<p>Creates a ones-filled NumPy array.</p> <p>Parameters: | Parameter | Type | Description | |-----------|------|-------------| | <code>shape</code> | <code>Tuple[int, int]</code> | (rows, cols) | | <code>dtype</code> | <code>str</code> or <code>None</code> | Optional data type |</p> <p>Returns: <code>numpy.ndarray</code></p> <p>Example:</p> <pre><code>from LinAlgKit import ones\nO = ones((2, 4))\n</code></pre>"},{"location":"api/#eyen-dtypenone","title":"<code>eye(n, dtype=None)</code>","text":"<p>Creates an identity matrix as a NumPy array.</p> <p>Parameters: | Parameter | Type | Description | |-----------|------|-------------| | <code>n</code> | <code>int</code> | Size of the square matrix | | <code>dtype</code> | <code>str</code> or <code>None</code> | Optional data type |</p> <p>Returns: <code>numpy.ndarray</code></p> <p>Example:</p> <pre><code>from LinAlgKit import eye\nI = eye(3)\n</code></pre>"},{"location":"api/#matmula-b","title":"<code>matmul(a, b)</code>","text":"<p>Performs matrix multiplication on NumPy arrays.</p> <p>Parameters: | Parameter | Type | Description | |-----------|------|-------------| | <code>a</code> | <code>array-like</code> | Left matrix | | <code>b</code> | <code>array-like</code> | Right matrix |</p> <p>Returns: <code>numpy.ndarray</code></p> <p>Example:</p> <pre><code>from LinAlgKit import array, matmul\nA = array([[1, 2], [3, 4]])\nB = array([[5, 6], [7, 8]])\nC = matmul(A, B)\nprint(C)\n# [[19 22]\n#  [43 50]]\n</code></pre>"},{"location":"api/#transposea","title":"<code>transpose(a)</code>","text":"<p>Transposes a NumPy array.</p> <p>Parameters: | Parameter | Type | Description | |-----------|------|-------------| | <code>a</code> | <code>array-like</code> | Input matrix |</p> <p>Returns: <code>numpy.ndarray</code></p> <p>Example:</p> <pre><code>from LinAlgKit import array, transpose\nA = array([[1, 2, 3], [4, 5, 6]])\nprint(transpose(A))\n# [[1 4]\n#  [2 5]\n#  [3 6]]\n</code></pre>"},{"location":"api/#tracea","title":"<code>trace(a)</code>","text":"<p>Computes the trace of a NumPy array.</p> <p>Parameters: | Parameter | Type | Description | |-----------|------|-------------| | <code>a</code> | <code>array-like</code> | Input matrix |</p> <p>Returns: <code>float</code></p> <p>Example:</p> <pre><code>from LinAlgKit import array, trace\nA = array([[1, 2], [3, 4]])\nprint(trace(A))  # 5.0\n</code></pre>"},{"location":"api/#deta","title":"<code>det(a)</code>","text":"<p>Computes the determinant of a NumPy array.</p> <p>Parameters: | Parameter | Type | Description | |-----------|------|-------------| | <code>a</code> | <code>array-like</code> | Input square matrix |</p> <p>Returns: <code>float</code></p> <p>Example:</p> <pre><code>from LinAlgKit import array, det\nA = array([[1, 2], [3, 4]])\nprint(det(A))  # -2.0\n</code></pre>"},{"location":"api/#examples","title":"Examples","text":""},{"location":"api/#example-1-solving-a-linear-system","title":"Example 1: Solving a Linear System","text":"<pre><code>import LinAlgKit as lk\nimport numpy as np\n\n# Solve Ax = b using NumPy's solver with LinAlgKit matrices\nA = lk.Matrix.from_numpy([[3, 1], [1, 2]])\nb = np.array([9, 8])\n\n# Convert to NumPy for solving\nx = np.linalg.solve(A.to_numpy(), b)\nprint(f\"Solution: {x}\")  # [2. 3.]\n</code></pre>"},{"location":"api/#example-2-matrix-powers","title":"Example 2: Matrix Powers","text":"<pre><code>import LinAlgKit as lk\n\nA = lk.Matrix.from_numpy([[1, 1], [1, 0]])\n\n# Compute A^n for Fibonacci numbers\ndef matrix_power(M, n):\n    result = lk.Matrix.identity(M.rows)\n    for _ in range(n):\n        result = result * M\n    return result\n\nA8 = matrix_power(A, 8)\nprint(A8.to_numpy())\n# [[34. 21.]\n#  [21. 13.]]\n# Fibonacci: 34 is F(9), 21 is F(8)\n</code></pre>"},{"location":"api/#example-3-checking-matrix-properties","title":"Example 3: Checking Matrix Properties","text":"<pre><code>import LinAlgKit as lk\nimport numpy as np\n\nA = lk.Matrix.from_numpy([[4, -2], [-2, 4]])\n\n# Check if symmetric\nAT = A.transpose()\nis_symmetric = np.allclose(A.to_numpy(), AT.to_numpy())\nprint(f\"Symmetric: {is_symmetric}\")  # True\n\n# Check if positive definite (all eigenvalues &gt; 0)\neigenvalues = np.linalg.eigvals(A.to_numpy())\nis_positive_definite = all(eigenvalues &gt; 0)\nprint(f\"Positive definite: {is_positive_definite}\")  # True\n</code></pre>"},{"location":"api/#error-handling","title":"Error Handling","text":""},{"location":"api/#common-errors","title":"Common Errors","text":"Error Cause Solution <code>ValueError: expected a 2D array</code> Passed 1D or 3D+ array to <code>from_numpy()</code> Reshape to 2D: <code>arr.reshape(m, n)</code> <code>ValueError: determinant is only defined for square matrices</code> Called <code>determinant_naive()</code> on non-square matrix Use only on square matrices Broadcasting errors Mismatched dimensions in arithmetic Ensure matrices have compatible shapes"},{"location":"api/#debugging-tips","title":"Debugging Tips","text":"<pre><code># Check matrix dimensions\nprint(f\"Shape: {A.rows} x {A.cols}\")\n\n# View underlying data\nprint(A.to_numpy())\n\n# Check data type\nprint(A.to_numpy().dtype)\n</code></pre>"},{"location":"api/#version-information","title":"Version Information","text":"<pre><code>import LinAlgKit\nprint(LinAlgKit.__version__)  # \"0.1.0\"\nprint(LinAlgKit.BACKEND)      # \"python\"\n</code></pre>"},{"location":"deep_learning/","title":"Deep Learning Functions Reference","text":"<p>LinAlgKit provides comprehensive mathematical functions for building neural networks and deep learning applications.</p>"},{"location":"deep_learning/#table-of-contents","title":"Table of Contents","text":"<ol> <li>Activation Functions</li> <li>Loss Functions</li> <li>Normalization</li> <li>Convolution Operations</li> <li>Weight Initialization</li> <li>Utility Functions</li> <li>Advanced Math</li> <li>Examples</li> </ol>"},{"location":"deep_learning/#activation-functions","title":"Activation Functions","text":""},{"location":"deep_learning/#sigmoidx","title":"sigmoid(x)","text":"<p>Sigmoid activation: \u03c3(x) = 1 / (1 + exp(-x))</p> <pre><code>import LinAlgKit as lk\nimport numpy as np\n\nx = np.array([-2, -1, 0, 1, 2])\noutput = lk.sigmoid(x)\n# [0.119, 0.269, 0.5, 0.731, 0.881]\n</code></pre> <p>Properties: - Output range: (0, 1) - Used for: Binary classification, gates in LSTMs</p>"},{"location":"deep_learning/#relux","title":"relu(x)","text":"<p>Rectified Linear Unit: ReLU(x) = max(0, x)</p> <pre><code>x = np.array([-2, -1, 0, 1, 2])\noutput = lk.relu(x)\n# [0, 0, 0, 1, 2]\n</code></pre> <p>Properties: - Output range: [0, \u221e) - Fast to compute - Can cause \"dying ReLU\" problem</p>"},{"location":"deep_learning/#leaky_relux-alpha001","title":"leaky_relu(x, alpha=0.01)","text":"<p>Leaky ReLU: f(x) = x if x &gt; 0, else \u03b1*x</p> <pre><code>x = np.array([-2, -1, 0, 1, 2])\noutput = lk.leaky_relu(x, alpha=0.1)\n# [-0.2, -0.1, 0, 1, 2]\n</code></pre> <p>Properties: - Prevents dying ReLU - \u03b1 typically 0.01 or 0.1</p>"},{"location":"deep_learning/#elux-alpha10","title":"elu(x, alpha=1.0)","text":"<p>Exponential Linear Unit: f(x) = x if x &gt; 0, else \u03b1*(exp(x) - 1)</p> <pre><code>x = np.array([-2, -1, 0, 1, 2])\noutput = lk.elu(x)\n# [-0.865, -0.632, 0, 1, 2]\n</code></pre> <p>Properties: - Smooth for negative values - Mean activations closer to zero</p>"},{"location":"deep_learning/#gelux","title":"gelu(x)","text":"<p>Gaussian Error Linear Unit (used in BERT, GPT):</p> <pre><code>x = np.array([-2, -1, 0, 1, 2])\noutput = lk.gelu(x)\n# [-0.045, -0.158, 0, 0.841, 1.955]\n</code></pre> <p>Properties: - Smooth, differentiable everywhere - Current state-of-the-art for transformers</p>"},{"location":"deep_learning/#swishx-beta10","title":"swish(x, beta=1.0)","text":"<p>Self-gated activation: f(x) = x * sigmoid(\u03b2*x)</p> <pre><code>output = lk.swish(x, beta=1.0)\n</code></pre> <p>Properties: - Smooth, non-monotonic - Outperforms ReLU in deep networks</p>"},{"location":"deep_learning/#softmaxx-axis-1","title":"softmax(x, axis=-1)","text":"<p>Converts logits to probabilities:</p> <pre><code>logits = np.array([[2.0, 1.0, 0.1]])\nprobs = lk.softmax(logits)\n# [[0.659, 0.242, 0.099]]  (sums to 1)\n</code></pre> <p>Properties: - Output sums to 1 - Used for multi-class classification</p>"},{"location":"deep_learning/#log_softmaxx-axis-1","title":"log_softmax(x, axis=-1)","text":"<p>Numerically stable log of softmax:</p> <pre><code>log_probs = lk.log_softmax(logits)\n</code></pre> <p>Use case: Computing cross-entropy loss efficiently</p>"},{"location":"deep_learning/#softplusx","title":"softplus(x)","text":"<p>Smooth approximation of ReLU: f(x) = log(1 + exp(x))</p> <pre><code>output = lk.softplus(x)\n</code></pre>"},{"location":"deep_learning/#tanhx","title":"tanh(x)","text":"<p>Hyperbolic tangent:</p> <pre><code>output = lk.tanh(x)\n# Range: (-1, 1)\n</code></pre>"},{"location":"deep_learning/#loss-functions","title":"Loss Functions","text":""},{"location":"deep_learning/#mse_losspredictions-targets-reductionmean","title":"mse_loss(predictions, targets, reduction='mean')","text":"<p>Mean Squared Error for regression:</p> <pre><code>pred = np.array([1.0, 2.0, 3.0])\ntarget = np.array([1.1, 2.2, 2.8])\nloss = lk.mse_loss(pred, target)\n# 0.03\n</code></pre>"},{"location":"deep_learning/#mae_losspredictions-targets-reductionmean","title":"mae_loss(predictions, targets, reduction='mean')","text":"<p>Mean Absolute Error (L1 loss):</p> <pre><code>loss = lk.mae_loss(pred, target)\n</code></pre>"},{"location":"deep_learning/#huber_losspredictions-targets-delta10-reductionmean","title":"huber_loss(predictions, targets, delta=1.0, reduction='mean')","text":"<p>Robust loss combining MSE and MAE:</p> <pre><code>loss = lk.huber_loss(pred, target, delta=1.0)\n</code></pre> <p>Properties: - Quadratic for small errors - Linear for large errors (robust to outliers)</p>"},{"location":"deep_learning/#cross_entropy_losspredictions-targets-epsilon1e-12","title":"cross_entropy_loss(predictions, targets, epsilon=1e-12)","text":"<p>Cross-entropy for multi-class classification:</p> <pre><code>probs = np.array([[0.7, 0.2, 0.1], [0.1, 0.8, 0.1]])\ntargets = np.array([0, 1])  # Class indices\nloss = lk.cross_entropy_loss(probs, targets)\n</code></pre>"},{"location":"deep_learning/#binary_cross_entropypredictions-targets-epsilon1e-12","title":"binary_cross_entropy(predictions, targets, epsilon=1e-12)","text":"<p>Binary cross-entropy for binary classification:</p> <pre><code>probs = np.array([0.9, 0.1, 0.8])\ntargets = np.array([1, 0, 1])\nloss = lk.binary_cross_entropy(probs, targets)\n</code></pre>"},{"location":"deep_learning/#normalization-functions","title":"Normalization Functions","text":""},{"location":"deep_learning/#batch_normx-gammanone-betanone-epsilon1e-5-axis0","title":"batch_norm(x, gamma=None, beta=None, epsilon=1e-5, axis=0)","text":"<p>Batch normalization:</p> <pre><code># x shape: (batch_size, features)\nx_norm = lk.batch_norm(x, gamma=scale, beta=shift)\n</code></pre> <p>Properties: - Normalizes across batch dimension - Reduces internal covariate shift</p>"},{"location":"deep_learning/#layer_normx-gammanone-betanone-epsilon1e-5","title":"layer_norm(x, gamma=None, beta=None, epsilon=1e-5)","text":"<p>Layer normalization (used in transformers):</p> <pre><code># Normalizes across feature dimension\nx_norm = lk.layer_norm(x)\n</code></pre> <p>Properties: - Normalizes across features, not batch - Works with any batch size</p>"},{"location":"deep_learning/#instance_normx-epsilon1e-5","title":"instance_norm(x, epsilon=1e-5)","text":"<p>Instance normalization (for style transfer):</p> <pre><code># x shape: (batch, channels, height, width)\nx_norm = lk.instance_norm(x)\n</code></pre>"},{"location":"deep_learning/#convolution-operations","title":"Convolution Operations","text":""},{"location":"deep_learning/#conv2dx-kernel-stride1-padding0","title":"conv2d(x, kernel, stride=1, padding=0)","text":"<p>2D convolution:</p> <pre><code># Input: (batch, channels, H, W) or (H, W)\n# Kernel: (out_channels, in_channels, kH, kW) or (kH, kW)\nimage = np.random.randn(1, 1, 28, 28)\nkernel = np.random.randn(32, 1, 3, 3)\noutput = lk.conv2d(image, kernel, stride=1, padding=1)\n# Output shape: (1, 32, 28, 28)\n</code></pre>"},{"location":"deep_learning/#max_pool2dx-kernel_size2-stridenone","title":"max_pool2d(x, kernel_size=2, stride=None)","text":"<p>Max pooling:</p> <pre><code>output = lk.max_pool2d(x, kernel_size=2)\n# Reduces spatial dimensions by half\n</code></pre>"},{"location":"deep_learning/#avg_pool2dx-kernel_size2-stridenone","title":"avg_pool2d(x, kernel_size=2, stride=None)","text":"<p>Average pooling:</p> <pre><code>output = lk.avg_pool2d(x, kernel_size=2)\n</code></pre>"},{"location":"deep_learning/#global_avg_pool2dx","title":"global_avg_pool2d(x)","text":"<p>Global average pooling:</p> <pre><code># Input: (batch, channels, H, W)\n# Output: (batch, channels)\noutput = lk.global_avg_pool2d(x)\n</code></pre>"},{"location":"deep_learning/#weight-initialization","title":"Weight Initialization","text":""},{"location":"deep_learning/#xavier_uniformshape-gain10","title":"xavier_uniform(shape, gain=1.0)","text":"<p>Xavier/Glorot uniform initialization (for tanh/sigmoid):</p> <pre><code>weights = lk.xavier_uniform((784, 256))\n</code></pre>"},{"location":"deep_learning/#xavier_normalshape-gain10","title":"xavier_normal(shape, gain=1.0)","text":"<p>Xavier/Glorot normal initialization:</p> <pre><code>weights = lk.xavier_normal((784, 256))\n</code></pre>"},{"location":"deep_learning/#he_uniformshape","title":"he_uniform(shape)","text":"<p>He/Kaiming uniform initialization (for ReLU):</p> <pre><code>weights = lk.he_uniform((784, 256))\n</code></pre>"},{"location":"deep_learning/#he_normalshape","title":"he_normal(shape)","text":"<p>He/Kaiming normal initialization:</p> <pre><code>weights = lk.he_normal((784, 256))\n</code></pre>"},{"location":"deep_learning/#utility-functions","title":"Utility Functions","text":""},{"location":"deep_learning/#dropoutx-p05-trainingtrue","title":"dropout(x, p=0.5, training=True)","text":"<p>Dropout regularization:</p> <pre><code># During training (randomly zeros elements)\nx_dropped = lk.dropout(x, p=0.5, training=True)\n\n# During inference (returns unchanged)\nx_out = lk.dropout(x, p=0.5, training=False)\n</code></pre>"},{"location":"deep_learning/#one_hotindices-num_classes","title":"one_hot(indices, num_classes)","text":"<p>One-hot encoding:</p> <pre><code>labels = np.array([0, 2, 1])\nencoded = lk.one_hot(labels, num_classes=3)\n# [[1, 0, 0],\n#  [0, 0, 1],\n#  [0, 1, 0]]\n</code></pre>"},{"location":"deep_learning/#clipx-min_val-max_val","title":"clip(x, min_val, max_val)","text":"<p>Clip values to a range:</p> <pre><code>x_clipped = lk.clip(x, -1.0, 1.0)\n</code></pre>"},{"location":"deep_learning/#flattenx-start_dim0","title":"flatten(x, start_dim=0)","text":"<p>Flatten tensor:</p> <pre><code># Input: (batch, C, H, W)\n# Output: (batch, C*H*W) if start_dim=1\nx_flat = lk.flatten(x, start_dim=1)\n</code></pre>"},{"location":"deep_learning/#reshapex-shape","title":"reshape(x, shape)","text":"<p>Reshape array:</p> <pre><code>x_reshaped = lk.reshape(x, (batch_size, -1))\n</code></pre>"},{"location":"deep_learning/#advanced-math-functions","title":"Advanced Math Functions","text":""},{"location":"deep_learning/#normalizex-axis-1-epsilon1e-12","title":"normalize(x, axis=-1, epsilon=1e-12)","text":"<p>L2 normalize along axis:</p> <pre><code>x_normalized = lk.normalize(x)\n# ||x|| = 1 along specified axis\n</code></pre>"},{"location":"deep_learning/#cosine_similaritya-b-axis-1","title":"cosine_similarity(a, b, axis=-1)","text":"<p>Cosine similarity:</p> <pre><code>similarity = lk.cosine_similarity(a, b)\n# Range: [-1, 1]\n</code></pre>"},{"location":"deep_learning/#euclidean_distancea-b-axis-1","title":"euclidean_distance(a, b, axis=-1)","text":"<p>Euclidean distance:</p> <pre><code>distance = lk.euclidean_distance(a, b)\n</code></pre>"},{"location":"deep_learning/#pairwise_distancesx-ynone","title":"pairwise_distances(X, Y=None)","text":"<p>Compute all pairwise distances:</p> <pre><code># X: (n, features), Y: (m, features)\n# Output: (n, m) distance matrix\ndistances = lk.pairwise_distances(X, Y)\n</code></pre>"},{"location":"deep_learning/#numerical_gradientf-x-epsilon1e-7","title":"numerical_gradient(f, x, epsilon=1e-7)","text":"<p>Compute numerical gradient:</p> <pre><code>def loss_fn(w):\n    return np.sum(w ** 2)\n\ngrad = lk.numerical_gradient(loss_fn, weights)\n</code></pre>"},{"location":"deep_learning/#outera-b","title":"outer(a, b)","text":"<p>Outer product:</p> <pre><code>result = lk.outer(a, b)  # a[:, None] * b[None, :]\n</code></pre>"},{"location":"deep_learning/#innera-b","title":"inner(a, b)","text":"<p>Inner product:</p> <pre><code>result = lk.inner(a, b)\n</code></pre>"},{"location":"deep_learning/#dota-b","title":"dot(a, b)","text":"<p>Dot product:</p> <pre><code>result = lk.dot(a, b)\n</code></pre>"},{"location":"deep_learning/#crossa-b","title":"cross(a, b)","text":"<p>Cross product (3D vectors):</p> <pre><code>result = lk.cross(a, b)\n</code></pre>"},{"location":"deep_learning/#examples","title":"Examples","text":""},{"location":"deep_learning/#example-1-simple-neural-network-forward-pass","title":"Example 1: Simple Neural Network Forward Pass","text":"<pre><code>import LinAlgKit as lk\nimport numpy as np\n\n# Initialize weights\nW1 = lk.he_normal((784, 128))\nW2 = lk.he_normal((128, 10))\n\n# Forward pass\ndef forward(x):\n    # Layer 1\n    h1 = lk.relu(x @ W1)\n    h1 = lk.dropout(h1, p=0.2, training=True)\n\n    # Layer 2\n    logits = h1 @ W2\n    probs = lk.softmax(logits)\n    return probs\n\n# Example input\nx = np.random.randn(32, 784)\noutput = forward(x)\nprint(f\"Output shape: {output.shape}\")  # (32, 10)\n</code></pre>"},{"location":"deep_learning/#example-2-convolutional-layer","title":"Example 2: Convolutional Layer","text":"<pre><code>import LinAlgKit as lk\nimport numpy as np\n\n# Input image batch\nimages = np.random.randn(16, 3, 32, 32)  # (batch, channels, H, W)\n\n# Convolution kernel\nkernel = lk.he_normal((64, 3, 3, 3))  # (out_ch, in_ch, kH, kW)\n\n# Forward pass\nconv_out = lk.conv2d(images, kernel, stride=1, padding=1)\nconv_out = lk.batch_norm(conv_out)\nconv_out = lk.relu(conv_out)\npooled = lk.max_pool2d(conv_out, kernel_size=2)\n\nprint(f\"After conv: {conv_out.shape}\")  # (16, 64, 32, 32)\nprint(f\"After pool: {pooled.shape}\")    # (16, 64, 16, 16)\n</code></pre>"},{"location":"deep_learning/#example-3-training-step-with-loss","title":"Example 3: Training Step with Loss","text":"<pre><code>import LinAlgKit as lk\nimport numpy as np\n\n# Predictions and targets\nlogits = np.random.randn(32, 10)\ntargets = np.random.randint(0, 10, size=32)\n\n# Compute loss\nprobs = lk.softmax(logits)\nloss = lk.cross_entropy_loss(probs, targets)\nprint(f\"Cross-entropy loss: {loss:.4f}\")\n\n# For regression\npredictions = np.random.randn(32, 1)\nregression_targets = np.random.randn(32, 1)\nmse = lk.mse_loss(predictions, regression_targets)\nprint(f\"MSE loss: {mse:.4f}\")\n</code></pre>"},{"location":"deep_learning/#function-reference-table","title":"Function Reference Table","text":"Category Functions Activations <code>sigmoid</code>, <code>relu</code>, <code>leaky_relu</code>, <code>elu</code>, <code>gelu</code>, <code>swish</code>, <code>softplus</code>, <code>tanh</code>, <code>softmax</code>, <code>log_softmax</code> Derivatives <code>sigmoid_derivative</code>, <code>relu_derivative</code>, <code>leaky_relu_derivative</code>, <code>elu_derivative</code>, <code>tanh_derivative</code> Losses <code>mse_loss</code>, <code>mae_loss</code>, <code>huber_loss</code>, <code>cross_entropy_loss</code>, <code>binary_cross_entropy</code> Normalization <code>batch_norm</code>, <code>layer_norm</code>, <code>instance_norm</code> Convolution <code>conv2d</code>, <code>max_pool2d</code>, <code>avg_pool2d</code>, <code>global_avg_pool2d</code> Initialization <code>xavier_uniform</code>, <code>xavier_normal</code>, <code>he_uniform</code>, <code>he_normal</code> Utilities <code>dropout</code>, <code>one_hot</code>, <code>clip</code>, <code>flatten</code>, <code>reshape</code> Math <code>normalize</code>, <code>cosine_similarity</code>, <code>euclidean_distance</code>, <code>pairwise_distances</code>, <code>numerical_gradient</code>, <code>outer</code>, <code>inner</code>, <code>dot</code>, <code>cross</code>, <code>norm</code> <p>For matrix operations, see API Reference.</p>"},{"location":"performance/","title":"Performance Guide","text":"<p>This page explains the performance characteristics of LinAlgKit and how to reproduce benchmark results.</p>"},{"location":"performance/#determinant-algorithms","title":"Determinant algorithms","text":"<ul> <li><code>determinant()</code>: Bareiss fraction-free LU with partial pivoting; O(n^3), stable for integer matrices.</li> <li><code>determinant_naive()</code>: Laplace expansion; O(n!) \u2014 only for tiny matrices/testing.</li> </ul>"},{"location":"performance/#running-benchmarks","title":"Running benchmarks","text":"<p>Build with benchmarks enabled and run the harness:</p> <pre><code>mkdir -p ~/matrixlib_build &amp;&amp; cd ~/matrixlib_build\ncmake -G \"Unix Makefiles\" -DBUILD_BENCHMARKS=ON /path/to/repo\ncmake --build . -j\npython3 /path/to/repo/scripts/run_benchmarks.py --build-dir . --csv results.csv --plot results.png\n</code></pre> <p>The harness saves a CSV from Google Benchmark and optionally a simple bar plot (if matplotlib is installed).</p>"},{"location":"performance/#interpreting-benchmark-output","title":"Interpreting benchmark output","text":"<ul> <li><code>real_time</code> is the per-iteration runtime (ns), averaged over repetitions.</li> <li>Determinant (optimized) should scale roughly with O(n^3).</li> <li>Determinant (naive) grows factorially; use only up to n\u22488.</li> </ul>"},{"location":"performance/#tips","title":"Tips","text":"<ul> <li>Build <code>Release</code> for meaningful numbers.</li> <li>Avoid running on a heavily loaded system.</li> <li>For multi-run studies, pin CPU frequency/governor and isolate cores if possible.</li> </ul>"},{"location":"releases/","title":"Release Notes","text":"<p>This document contains detailed release notes for each version of LinAlgKit.</p>"},{"location":"releases/#v021-performance-optimizations-2025-12-24","title":"v0.2.1 - Performance Optimizations (2025-12-24)","text":""},{"location":"releases/#performance-improvements","title":"\ud83d\ude80 Performance Improvements","text":"<p>This release introduces significant performance optimizations using Numba JIT compilation.</p>"},{"location":"releases/#benchmark-results-5m-elements","title":"Benchmark Results (5M elements)","text":"Function Standard Fast (JIT) Speedup <code>mse_loss</code> 33.75ms 2.82ms 12.0x <code>mae_loss</code> 34.86ms 2.67ms 13.1x <code>leaky_relu</code> 30.16ms 6.81ms 4.4x <code>gelu</code> 200.78ms 76.44ms 2.6x <code>tanh</code> 37.33ms 15.29ms 2.4x <code>swish</code> 100.27ms 54.62ms 1.8x <code>elu</code> 65.14ms 40.06ms 1.6x <code>sigmoid</code> 80.98ms 54.71ms 1.5x <code>softplus</code> 108.80ms 70.88ms 1.5x"},{"location":"releases/#new-features","title":"New Features","text":""},{"location":"releases/#fast-module","title":"<code>fast</code> Module","text":"<p>A new high-performance module with Numba JIT-compiled functions:</p> <pre><code>from LinAlgKit import fast\n\n# 12x faster loss computation\nloss = fast.fast_mse_loss(predictions, targets)\n\n# 4.4x faster activation\noutput = fast.fast_leaky_relu(x, alpha=0.01)\n</code></pre> <p>Available fast functions: - <code>fast_sigmoid</code>, <code>fast_relu</code>, <code>fast_leaky_relu</code>, <code>fast_elu</code> - <code>fast_gelu</code>, <code>fast_swish</code>, <code>fast_tanh</code>, <code>fast_softplus</code> - <code>fast_mse_loss</code>, <code>fast_mae_loss</code>, <code>fast_normalize</code></p>"},{"location":"releases/#in-place-operations","title":"In-Place Operations","text":"<p>New in-place methods that avoid memory allocation:</p> <pre><code>A.add_(B)      # A += B in-place\nA.sub_(B)      # A -= B in-place\nA.mul_(2.0)    # A *= 2.0 in-place\nA.hadamard_(B) # Element-wise multiply in-place\n</code></pre>"},{"location":"releases/#zero-copy-access","title":"Zero-Copy Access","text":"<ul> <li><code>.T</code> property - Transpose view (no copy)</li> <li><code>to_numpy_view()</code> - Direct array access (no copy)</li> <li><code>transpose(copy=False)</code> - Optional zero-copy transpose</li> </ul>"},{"location":"releases/#dependencies","title":"Dependencies","text":"<ul> <li>Optional: <code>numba&gt;=0.57.0</code> (for JIT acceleration)</li> </ul>"},{"location":"releases/#v020-deep-learning-expansion-2025-12-24","title":"v0.2.0 - Deep Learning Expansion (2025-12-24)","text":""},{"location":"releases/#deep-learning-functions","title":"\ud83e\udde0 Deep Learning Functions","text":"<p>Major expansion with 50+ mathematical functions for deep learning.</p>"},{"location":"releases/#activation-functions","title":"Activation Functions","text":"<ul> <li><code>sigmoid</code>, <code>relu</code>, <code>leaky_relu</code>, <code>elu</code>, <code>gelu</code>, <code>swish</code></li> <li><code>softplus</code>, <code>tanh</code>, <code>softmax</code>, <code>log_softmax</code></li> <li>Derivative functions for backpropagation</li> </ul>"},{"location":"releases/#loss-functions","title":"Loss Functions","text":"<ul> <li><code>mse_loss</code> - Mean Squared Error</li> <li><code>mae_loss</code> - Mean Absolute Error</li> <li><code>huber_loss</code> - Robust loss</li> <li><code>cross_entropy_loss</code> - Multi-class classification</li> <li><code>binary_cross_entropy</code> - Binary classification</li> </ul>"},{"location":"releases/#normalization","title":"Normalization","text":"<ul> <li><code>batch_norm</code> - Batch normalization</li> <li><code>layer_norm</code> - Layer normalization (transformers)</li> <li><code>instance_norm</code> - Instance normalization (style transfer)</li> </ul>"},{"location":"releases/#convolution-operations","title":"Convolution Operations","text":"<ul> <li><code>conv2d</code> - 2D convolution</li> <li><code>max_pool2d</code>, <code>avg_pool2d</code> - Pooling</li> <li><code>global_avg_pool2d</code> - Global average pooling</li> </ul>"},{"location":"releases/#weight-initialization","title":"Weight Initialization","text":"<ul> <li><code>xavier_uniform</code>, <code>xavier_normal</code> - For tanh/sigmoid</li> <li><code>he_uniform</code>, <code>he_normal</code> - For ReLU networks</li> </ul>"},{"location":"releases/#utility-functions","title":"Utility Functions","text":"<ul> <li><code>dropout</code>, <code>one_hot</code>, <code>clip</code>, <code>flatten</code>, <code>reshape</code></li> <li><code>normalize</code>, <code>cosine_similarity</code>, <code>euclidean_distance</code></li> <li><code>pairwise_distances</code>, <code>numerical_gradient</code></li> </ul>"},{"location":"releases/#matrix-decompositions","title":"Matrix Decompositions","text":"<ul> <li><code>lu()</code> - LU decomposition with partial pivoting</li> <li><code>qr()</code> - QR decomposition</li> <li><code>cholesky()</code> - Cholesky decomposition</li> <li><code>svd()</code> - Singular Value Decomposition</li> </ul>"},{"location":"releases/#eigenvalue-methods","title":"Eigenvalue Methods","text":"<ul> <li><code>eig()</code> - Eigenvalues and eigenvectors</li> <li><code>eigvals()</code> - Eigenvalues only</li> <li><code>eigh()</code> - Symmetric eigenvalue decomposition</li> </ul>"},{"location":"releases/#linear-solvers","title":"Linear Solvers","text":"<ul> <li><code>solve()</code> - Solve Ax = b</li> <li><code>inv()</code> - Matrix inverse</li> <li><code>pinv()</code> - Moore-Penrose pseudoinverse</li> <li><code>lstsq()</code> - Least-squares solution</li> </ul>"},{"location":"releases/#matrix-analysis","title":"Matrix Analysis","text":"<ul> <li><code>norm()</code> - Multiple norm types</li> <li><code>cond()</code> - Condition number</li> <li><code>rank()</code> - Matrix rank</li> </ul>"},{"location":"releases/#v010-initial-release-2025-12-24","title":"v0.1.0 - Initial Release (2025-12-24)","text":""},{"location":"releases/#core-features","title":"Core Features","text":""},{"location":"releases/#matrix-classes","title":"Matrix Classes","text":"<ul> <li><code>Matrix</code> - Double-precision (float64)</li> <li><code>MatrixF</code> - Single-precision (float32)</li> <li><code>MatrixI</code> - Integer matrix</li> </ul>"},{"location":"releases/#static-constructors","title":"Static Constructors","text":"<pre><code>Matrix.identity(3)   # 3x3 identity\nMatrix.zeros(2, 3)   # 2x3 zeros\nMatrix.ones(4, 4)    # 4x4 ones\n</code></pre>"},{"location":"releases/#matrix-operations","title":"Matrix Operations","text":"<ul> <li><code>transpose()</code> - Transposition</li> <li><code>trace()</code> - Sum of diagonal</li> <li><code>determinant()</code> - LU-based O(n\u00b3)</li> <li><code>determinant_naive()</code> - Recursive (small matrices)</li> </ul>"},{"location":"releases/#arithmetic-operators","title":"Arithmetic Operators","text":"<ul> <li><code>A + B</code> - Element-wise addition</li> <li><code>A - B</code> - Element-wise subtraction</li> <li><code>A * B</code> - Matrix multiplication</li> <li><code>2 * A</code> - Scalar multiplication</li> </ul>"},{"location":"releases/#numpy-interoperability","title":"NumPy Interoperability","text":"<pre><code># From NumPy\nA = Matrix.from_numpy(np_array)\n\n# To NumPy\nnp_array = A.to_numpy()\n</code></pre>"},{"location":"releases/#element-access","title":"Element Access","text":"<pre><code>val = A[i, j]    # Get element\nA[i, j] = 5.0    # Set element\n</code></pre>"},{"location":"releases/#upgrade-guide","title":"Upgrade Guide","text":""},{"location":"releases/#from-v010-to-v020","title":"From v0.1.0 to v0.2.0","text":"<p>No breaking changes. All v0.1.0 code works unchanged.</p> <p>New imports available:</p> <pre><code>import LinAlgKit as lk\n\n# New activation functions\noutput = lk.relu(x)\noutput = lk.softmax(logits)\n\n# New matrix methods\nL = A.cholesky()\neigenvalues, eigenvectors = A.eig()\nx = A.solve(b)\n</code></pre>"},{"location":"releases/#from-v020-to-v021","title":"From v0.2.0 to v0.2.1","text":"<p>No breaking changes. Install <code>numba</code> for automatic acceleration:</p> <pre><code>pip install numba\n</code></pre> <p>Use fast module for best performance:</p> <pre><code>from LinAlgKit import fast\n\n# Check if Numba is available\nimport LinAlgKit as lk\nprint(lk.HAS_NUMBA)  # True if numba installed\n</code></pre>"},{"location":"releases/#roadmap","title":"Roadmap","text":"<p>See EXPANSION_PLAN.md for the complete roadmap.</p>"},{"location":"releases/#upcoming-features","title":"Upcoming Features","text":"<p>v0.3.0 (Q1 2025) - Sparse matrix support (CSR, COO) - Iterative solvers (CG, GMRES) - Matrix functions (expm, logm, sqrtm)</p> <p>v0.4.0 (Q2 2025) - C++/Rust native core - BLAS/LAPACK integration - GPU acceleration (CUDA)</p> <p>v1.0.0 (2027) - Production-ready - Multi-backend support - Distributed computing</p>"},{"location":"releasing/","title":"Releasing LinAlgKit","text":"<p>This document describes how to cut a new release, publish wheels to TestPyPI or PyPI, and verify the artifacts.</p>"},{"location":"releasing/#versioning","title":"Versioning","text":"<ul> <li>Bump the version in <code>pyproject.toml</code> under <code>[project] version</code>.</li> <li>Use tags of the form:</li> <li>Pre-release (goes to TestPyPI): <code>vX.Y.ZrcN</code>, <code>vX.Y.ZaN</code>, <code>vX.Y.ZbN</code>, or <code>vX.Y.ZdevN</code></li> <li>Stable (goes to PyPI): <code>vX.Y.Z</code></li> </ul>"},{"location":"releasing/#pre-release-checklist","title":"Pre-release checklist","text":"<ul> <li>Ensure CI is green on <code>main</code>.</li> <li>Update <code>README.md</code> and <code>CHANGELOG</code> (if present).</li> <li>Smoke test locally:   ```bash   # Build C++   mkdir -p ~/matrixlib_build &amp;&amp; cd ~/matrixlib_build   cmake -G \"Unix Makefiles\" -DBUILD_TESTS=ON -DBUILD_BENCHMARKS=OFF -DPYTHON_EXECUTABLE=$(which python3) /path/to/repo   cmake --build . -j   ctest --output-on-failure</li> </ul> <p># Python editable install &amp; smoke import   pip install -U pip scikit-build-core pybind11 numpy   pip install -e /path/to/repo   python - &lt;&lt;'PY' import LinAlgKit as lk m = lk.Matrix(2,2,1.0) print(\"OK:\", m.to_numpy().shape) PY   ```</p>"},{"location":"releasing/#testpypi-publish-optional-recommended","title":"TestPyPI publish (optional, recommended)","text":"<p>1) Build artifacts locally</p> <pre><code>python -m pip install -U build twine\npython -m build\n</code></pre> <p>2) Upload to TestPyPI</p> <pre><code># Create a token at https://test.pypi.org/account/ and set TWINE_PASSWORD env var\npython -m twine upload -r testpypi dist/*\n</code></pre> <p>3) Verify install from TestPyPI in a clean venv</p> <pre><code>python -m venv .venv &amp;&amp; source .venv/bin/activate\npip install -i https://test.pypi.org/simple/ LinAlgKit\npython - &lt;&lt;'PY'\nimport LinAlgKit as lk\nprint(lk.Matrix(2,2,1.0).to_numpy())\nPY\n</code></pre>"},{"location":"releasing/#github-actions-publish-recommended","title":"GitHub Actions publish (recommended)","text":"<p>Publishing is automated via <code>.github/workflows/release.yml</code>:</p> <ul> <li>On pushing a tag <code>v*</code>, the workflow builds wheels (Linux/macOS/Windows) and an sdist.</li> <li>It uploads to TestPyPI for pre-release tags and PyPI for stable tags.</li> </ul>"},{"location":"releasing/#required-repository-secrets","title":"Required repository secrets","text":"<ul> <li><code>PYPI_API_TOKEN</code>: PyPI token with upload permissions.</li> <li><code>TEST_PYPI_API_TOKEN</code>: TestPyPI token with upload permissions.</li> </ul>"},{"location":"releasing/#triggering-a-release","title":"Triggering a release","text":"<pre><code>git tag v0.1.0rc1   # pre-release -&gt; TestPyPI\ngit push --tags\n# or stable\ngit tag v0.1.0\ngit push --tags\n</code></pre>"},{"location":"releasing/#post-release-verification","title":"Post-release verification","text":"<ul> <li>Install from the appropriate index:</li> </ul> <pre><code># Stable from PyPI\npip install LinAlgKit\n# Pre-release from TestPyPI\npip install -i https://test.pypi.org/simple/ LinAlgKit\n</code></pre> <ul> <li>Run a smoke test import and a small operation.</li> </ul>"},{"location":"releasing/#troubleshooting","title":"Troubleshooting","text":"<ul> <li>Missing <code>cmake</code>/compiler during build-from-source:</li> <li>Linux: <code>sudo apt-get install -y cmake build-essential python3-dev</code></li> <li>macOS: <code>xcode-select --install</code> (Command Line Tools)</li> <li>Windows: Visual Studio Build Tools (Desktop C++ workload)</li> <li>NumPy headers not found:</li> <li><code>pip install -U numpy</code> before installing LinAlgKit</li> <li>Windows/WSL file locks:</li> <li>Build in WSL <code>$HOME</code> and point CMake to Windows path instead of building on <code>/mnt/c</code>.</li> </ul>"},{"location":"tutorial/","title":"LinAlgKit Tutorial","text":"<p>A comprehensive guide to using LinAlgKit for linear algebra operations in Python.</p>"},{"location":"tutorial/#table-of-contents","title":"Table of Contents","text":"<ol> <li>Installation</li> <li>Getting Started</li> <li>Creating Matrices</li> <li>Basic Operations</li> <li>Matrix Analysis</li> <li>Working with NumPy</li> <li>Practical Examples</li> <li>Tips and Best Practices</li> </ol>"},{"location":"tutorial/#installation","title":"Installation","text":""},{"location":"tutorial/#from-pypi-recommended","title":"From PyPI (Recommended)","text":"<pre><code>pip install LinAlgKit\n</code></pre>"},{"location":"tutorial/#from-source","title":"From Source","text":"<pre><code>git clone https://github.com/SciComputeOrg/LinAlgKit.git\ncd LinAlgKit\npip install -e .\n</code></pre>"},{"location":"tutorial/#verify-installation","title":"Verify Installation","text":"<pre><code>import LinAlgKit as lk\nprint(f\"LinAlgKit version: {lk.__version__}\")\nprint(f\"Backend: {lk.BACKEND}\")\n</code></pre>"},{"location":"tutorial/#getting-started","title":"Getting Started","text":"<p>LinAlgKit provides a clean, Pythonic interface for matrix operations:</p> <pre><code>import LinAlgKit as lk\nimport numpy as np\n\n# Create a 2x2 matrix\nA = lk.Matrix.from_numpy([[1, 2], [3, 4]])\n\n# Create an identity matrix\nI = lk.Matrix.identity(2)\n\n# Perform operations\nresult = A + I\nprint(result.to_numpy())\n# [[2. 2.]\n#  [3. 5.]]\n</code></pre>"},{"location":"tutorial/#creating-matrices","title":"Creating Matrices","text":""},{"location":"tutorial/#method-1-from-dimensions","title":"Method 1: From Dimensions","text":"<p>Create a matrix with specified dimensions and optional fill value:</p> <pre><code>import LinAlgKit as lk\n\n# 3x3 zero matrix\nzeros = lk.Matrix(3, 3)\nprint(zeros.to_numpy())\n# [[0. 0. 0.]\n#  [0. 0. 0.]\n#  [0. 0. 0.]]\n\n# 2x4 matrix filled with 5.0\nfilled = lk.Matrix(2, 4, 5.0)\nprint(filled.to_numpy())\n# [[5. 5. 5. 5.]\n#  [5. 5. 5. 5.]]\n</code></pre>"},{"location":"tutorial/#method-2-from-numpy-arrays","title":"Method 2: From NumPy Arrays","text":"<p>Import existing NumPy arrays directly:</p> <pre><code>import numpy as np\nimport LinAlgKit as lk\n\n# From a NumPy array\narr = np.array([[1.0, 2.0, 3.0],\n                [4.0, 5.0, 6.0],\n                [7.0, 8.0, 9.0]])\nA = lk.Matrix.from_numpy(arr)\n\n# From a Python list (converted automatically)\nB = lk.Matrix.from_numpy([[1, 2], [3, 4]])\n</code></pre>"},{"location":"tutorial/#method-3-static-constructors","title":"Method 3: Static Constructors","text":"<p>Use convenient factory methods:</p> <pre><code>import LinAlgKit as lk\n\n# Identity matrix\nI = lk.Matrix.identity(3)\nprint(I.to_numpy())\n# [[1. 0. 0.]\n#  [0. 1. 0.]\n#  [0. 0. 1.]]\n\n# Zero matrix\nZ = lk.Matrix.zeros(2, 3)\nprint(Z.to_numpy())\n# [[0. 0. 0.]\n#  [0. 0. 0.]]\n\n# Ones matrix\nO = lk.Matrix.ones(2, 3)\nprint(O.to_numpy())\n# [[1. 1. 1.]\n#  [1. 1. 1.]]\n</code></pre>"},{"location":"tutorial/#choosing-the-right-type","title":"Choosing the Right Type","text":"<p>LinAlgKit offers three matrix types:</p> <pre><code>import LinAlgKit as lk\nimport numpy as np\n\n# Matrix - double precision (float64) - default choice\nA = lk.Matrix.from_numpy([[1.0, 2.0], [3.0, 4.0]])\n\n# MatrixF - single precision (float32) - memory efficient\nB = lk.MatrixF.from_numpy(np.array([[1, 2], [3, 4]], dtype=np.float32))\n\n# MatrixI - integer - for discrete math\nC = lk.MatrixI.from_numpy([[1, 0], [0, 1]])\n</code></pre> Type When to Use <code>Matrix</code> General purpose, high precision needed <code>MatrixF</code> Large matrices, GPU compatibility <code>MatrixI</code> Graph algorithms, counting, indexing"},{"location":"tutorial/#basic-operations","title":"Basic Operations","text":""},{"location":"tutorial/#matrix-addition-and-subtraction","title":"Matrix Addition and Subtraction","text":"<pre><code>import LinAlgKit as lk\n\nA = lk.Matrix.from_numpy([[1, 2], [3, 4]])\nB = lk.Matrix.from_numpy([[5, 6], [7, 8]])\n\n# Addition\nC = A + B\nprint(\"A + B =\")\nprint(C.to_numpy())\n# [[ 6.  8.]\n#  [10. 12.]]\n\n# Subtraction  \nD = A - B\nprint(\"A - B =\")\nprint(D.to_numpy())\n# [[-4. -4.]\n#  [-4. -4.]]\n</code></pre>"},{"location":"tutorial/#matrix-multiplication","title":"Matrix Multiplication","text":"<pre><code>import LinAlgKit as lk\n\nA = lk.Matrix.from_numpy([[1, 2], [3, 4]])\nB = lk.Matrix.from_numpy([[5, 6], [7, 8]])\n\n# Matrix multiplication (A @ B)\nC = A * B\nprint(\"A \u00d7 B =\")\nprint(C.to_numpy())\n# [[19. 22.]\n#  [43. 50.]]\n</code></pre>"},{"location":"tutorial/#scalar-multiplication","title":"Scalar Multiplication","text":"<pre><code>import LinAlgKit as lk\n\nA = lk.Matrix.from_numpy([[1, 2], [3, 4]])\n\n# Scalar on right\nB = A * 3\nprint(\"A \u00d7 3 =\")\nprint(B.to_numpy())\n# [[ 3.  6.]\n#  [ 9. 12.]]\n\n# Scalar on left\nC = 2 * A\nprint(\"2 \u00d7 A =\")\nprint(C.to_numpy())\n# [[2. 4.]\n#  [6. 8.]]\n</code></pre>"},{"location":"tutorial/#transpose","title":"Transpose","text":"<pre><code>import LinAlgKit as lk\n\nA = lk.Matrix.from_numpy([[1, 2, 3],\n                          [4, 5, 6]])\nprint(\"A =\")\nprint(A.to_numpy())\n# [[1. 2. 3.]\n#  [4. 5. 6.]]\n\nAT = A.transpose()\nprint(\"A^T =\")\nprint(AT.to_numpy())\n# [[1. 4.]\n#  [2. 5.]\n#  [3. 6.]]\n</code></pre>"},{"location":"tutorial/#matrix-analysis","title":"Matrix Analysis","text":""},{"location":"tutorial/#trace","title":"Trace","text":"<p>The trace is the sum of diagonal elements:</p> <pre><code>import LinAlgKit as lk\n\nA = lk.Matrix.from_numpy([[1, 2, 3],\n                          [4, 5, 6],\n                          [7, 8, 9]])\n\ntr = A.trace()\nprint(f\"trace(A) = {tr}\")  # 15.0 (1 + 5 + 9)\n</code></pre>"},{"location":"tutorial/#determinant","title":"Determinant","text":"<p>The determinant indicates whether a matrix is invertible:</p> <pre><code>import LinAlgKit as lk\n\n# Invertible matrix (det \u2260 0)\nA = lk.Matrix.from_numpy([[1, 2], [3, 4]])\nprint(f\"det(A) = {A.determinant()}\")  # -2.0\n\n# Singular matrix (det = 0)\nB = lk.Matrix.from_numpy([[1, 2], [2, 4]])\nprint(f\"det(B) = {B.determinant()}\")  # 0.0\n\n# 3x3 matrix\nC = lk.Matrix.from_numpy([[1, 2, 3],\n                          [4, 5, 6],\n                          [7, 8, 9]])\nprint(f\"det(C) = {C.determinant()}\")  # ~0.0 (singular)\n</code></pre>"},{"location":"tutorial/#element-access","title":"Element Access","text":"<pre><code>import LinAlgKit as lk\n\nA = lk.Matrix.from_numpy([[1, 2, 3],\n                          [4, 5, 6]])\n\n# Get element (0-indexed)\nprint(A[0, 0])  # 1.0\nprint(A[1, 2])  # 6.0\n\n# Set element\nA[0, 0] = 10.0\nprint(A.to_numpy())\n# [[10.  2.  3.]\n#  [ 4.  5.  6.]]\n</code></pre>"},{"location":"tutorial/#matrix-properties","title":"Matrix Properties","text":"<pre><code>import LinAlgKit as lk\n\nA = lk.Matrix.from_numpy([[1, 2, 3],\n                          [4, 5, 6]])\n\nprint(f\"Rows: {A.rows}\")     # 2\nprint(f\"Columns: {A.cols}\")  # 3\n</code></pre>"},{"location":"tutorial/#working-with-numpy","title":"Working with NumPy","text":""},{"location":"tutorial/#converting-between-linalgkit-and-numpy","title":"Converting Between LinAlgKit and NumPy","text":"<pre><code>import numpy as np\nimport LinAlgKit as lk\n\n# NumPy \u2192 LinAlgKit\nnp_array = np.random.rand(3, 3)\nlk_matrix = lk.Matrix.from_numpy(np_array)\n\n# LinAlgKit \u2192 NumPy\nback_to_numpy = lk_matrix.to_numpy()\n\n# Verify\nprint(np.allclose(np_array, back_to_numpy))  # True\n</code></pre>"},{"location":"tutorial/#using-linalgkit-with-numpy-functions","title":"Using LinAlgKit with NumPy Functions","text":"<pre><code>import numpy as np\nimport LinAlgKit as lk\n\nA = lk.Matrix.from_numpy([[4, -2], [-2, 4]])\n\n# Use NumPy's advanced functions on LinAlgKit matrices\neigenvalues = np.linalg.eigvals(A.to_numpy())\nprint(f\"Eigenvalues: {eigenvalues}\")  # [6. 2.]\n\nrank = np.linalg.matrix_rank(A.to_numpy())\nprint(f\"Rank: {rank}\")  # 2\n</code></pre>"},{"location":"tutorial/#functional-api","title":"Functional API","text":"<p>LinAlgKit provides NumPy-compatible functional helpers:</p> <pre><code>from LinAlgKit import array, zeros, ones, eye, matmul, transpose, trace, det\n\n# Create arrays\nA = array([[1, 2], [3, 4]])\nI = eye(2)\nZ = zeros((3, 3))\n\n# Operations\nB = matmul(A, I)\nprint(transpose(A))\nprint(f\"trace: {trace(A)}\")\nprint(f\"det: {det(A)}\")\n</code></pre>"},{"location":"tutorial/#practical-examples","title":"Practical Examples","text":""},{"location":"tutorial/#example-1-computing-powers-of-a-matrix","title":"Example 1: Computing Powers of a Matrix","text":"<pre><code>import LinAlgKit as lk\n\ndef matrix_power(A, n):\n    \"\"\"Compute A^n\"\"\"\n    result = lk.Matrix.identity(A.rows)\n    for _ in range(n):\n        result = result * A\n    return result\n\nA = lk.Matrix.from_numpy([[1, 1], [1, 0]])\nA5 = matrix_power(A, 5)\nprint(\"A^5 =\")\nprint(A5.to_numpy())\n# [[8. 5.]\n#  [5. 3.]]  - Fibonacci numbers!\n</code></pre>"},{"location":"tutorial/#example-2-gram-schmidt-orthogonalization","title":"Example 2: Gram-Schmidt Orthogonalization","text":"<pre><code>import numpy as np\nimport LinAlgKit as lk\n\ndef gram_schmidt(A):\n    \"\"\"Orthogonalize columns of A\"\"\"\n    m, n = A.rows, A.cols\n    Q = lk.Matrix.zeros(m, n)\n    np_A = A.to_numpy()\n    np_Q = Q.to_numpy()\n\n    for j in range(n):\n        v = np_A[:, j].copy()\n        for i in range(j):\n            v -= np.dot(np_Q[:, i], np_A[:, j]) * np_Q[:, i]\n        np_Q[:, j] = v / np.linalg.norm(v)\n\n    return lk.Matrix.from_numpy(np_Q)\n\nA = lk.Matrix.from_numpy([[1, 1], [0, 1], [1, 0]])\nQ = gram_schmidt(A)\nprint(\"Orthogonal Q:\")\nprint(Q.to_numpy())\n</code></pre>"},{"location":"tutorial/#example-3-checking-matrix-properties","title":"Example 3: Checking Matrix Properties","text":"<pre><code>import numpy as np\nimport LinAlgKit as lk\n\ndef analyze_matrix(A):\n    \"\"\"Print various properties of a matrix\"\"\"\n    np_A = A.to_numpy()\n\n    print(f\"Shape: {A.rows} \u00d7 {A.cols}\")\n    print(f\"Trace: {A.trace()}\")\n\n    if A.rows == A.cols:\n        print(f\"Determinant: {A.determinant()}\")\n\n        # Check symmetry\n        AT = A.transpose().to_numpy()\n        is_symmetric = np.allclose(np_A, AT)\n        print(f\"Symmetric: {is_symmetric}\")\n\n        # Check if identity\n        I = np.eye(A.rows)\n        is_identity = np.allclose(np_A, I)\n        print(f\"Is Identity: {is_identity}\")\n\n# Analyze a matrix\nA = lk.Matrix.from_numpy([[4, -2, 0],\n                          [-2, 4, -2],\n                          [0, -2, 4]])\nanalyze_matrix(A)\n</code></pre>"},{"location":"tutorial/#example-4-building-a-transformation-matrix","title":"Example 4: Building a Transformation Matrix","text":"<pre><code>import numpy as np\nimport LinAlgKit as lk\n\ndef rotation_matrix_2d(theta):\n    \"\"\"Create a 2D rotation matrix for angle theta (radians)\"\"\"\n    c, s = np.cos(theta), np.sin(theta)\n    return lk.Matrix.from_numpy([[c, -s], [s, c]])\n\ndef scale_matrix_2d(sx, sy):\n    \"\"\"Create a 2D scaling matrix\"\"\"\n    return lk.Matrix.from_numpy([[sx, 0], [0, sy]])\n\n# 45-degree rotation\nR = rotation_matrix_2d(np.pi / 4)\nprint(\"Rotation (45\u00b0):\")\nprint(R.to_numpy())\n\n# Scale by 2x horizontally, 0.5x vertically\nS = scale_matrix_2d(2, 0.5)\nprint(\"Scale:\")\nprint(S.to_numpy())\n\n# Combined transformation (scale then rotate)\nT = R * S\nprint(\"Combined:\")\nprint(T.to_numpy())\n</code></pre>"},{"location":"tutorial/#tips-and-best-practices","title":"Tips and Best Practices","text":""},{"location":"tutorial/#1-use-static-constructors-for-common-matrices","title":"1. Use Static Constructors for Common Matrices","text":"<pre><code># Good - clear and efficient\nI = lk.Matrix.identity(3)\nZ = lk.Matrix.zeros(2, 4)\n\n# Less clear\nI = lk.Matrix.from_numpy(np.eye(3))\nZ = lk.Matrix(2, 4, 0)\n</code></pre>"},{"location":"tutorial/#2-check-dimensions-before-operations","title":"2. Check Dimensions Before Operations","text":"<pre><code>def safe_multiply(A, B):\n    if A.cols != B.rows:\n        raise ValueError(f\"Cannot multiply {A.rows}\u00d7{A.cols} by {B.rows}\u00d7{B.cols}\")\n    return A * B\n</code></pre>"},{"location":"tutorial/#3-use-the-right-matrix-type","title":"3. Use the Right Matrix Type","text":"<pre><code># For precision-critical calculations\nA = lk.Matrix.from_numpy(precise_data)  # float64\n\n# For large datasets where memory matters\nB = lk.MatrixF.from_numpy(large_data)  # float32\n\n# For counting/graph operations\nC = lk.MatrixI.from_numpy(adjacency)  # int\n</code></pre>"},{"location":"tutorial/#4-leverage-numpy-for-advanced-operations","title":"4. Leverage NumPy for Advanced Operations","text":"<p>LinAlgKit focuses on the essentials. For advanced operations, convert to NumPy:</p> <pre><code>import numpy as np\nimport LinAlgKit as lk\n\nA = lk.Matrix.from_numpy([[1, 2], [3, 4]])\n\n# SVD (not in LinAlgKit yet)\nU, S, Vt = np.linalg.svd(A.to_numpy())\n\n# Eigendecomposition\neigenvalues, eigenvectors = np.linalg.eig(A.to_numpy())\n</code></pre>"},{"location":"tutorial/#5-remember-copy-semantics","title":"5. Remember Copy Semantics","text":"<p><code>from_numpy()</code> and <code>to_numpy()</code> both create copies:</p> <pre><code>arr = np.array([[1, 2], [3, 4]])\nA = lk.Matrix.from_numpy(arr)\n\n# Modifying arr does NOT affect A\narr[0, 0] = 999\nprint(A[0, 0])  # Still 1.0\n\n# Modifying the returned array does NOT affect A\nresult = A.to_numpy()\nresult[0, 0] = 888\nprint(A[0, 0])  # Still 1.0\n</code></pre>"},{"location":"tutorial/#next-steps","title":"Next Steps","text":"<ul> <li>Read the full API Reference for detailed method documentation</li> <li>Check the Performance Guide for optimization tips</li> <li>See FUTURE_UPDATES.md for upcoming features</li> <li>Contribute on GitHub</li> </ul> <p>Happy computing! \ud83e\uddee</p>"}]}